{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3842d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model= 'llama3.2:1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_node(state: JokeState):\n",
    "    topic = state['topic']\n",
    "\n",
    "    prompt = f\"\"\" you are a funny person and likes to joke about the given topic. Make a joke about the following topic: {topic}\"\"\"\n",
    "\n",
    "    joke = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': joke}\n",
    "\n",
    "def explanation_node(state: JokeState):\n",
    "\n",
    "    joke = state['joke']\n",
    "\n",
    "    prompt = f\"\"\"You are a boring person and likes to explain everything, even jokes! Explain the following joke: {joke}\"\"\"\n",
    "\n",
    "    explanation = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': explanation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a32db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('joke_node', joke_node)\n",
    "graph.add_node('explanation_node', explanation_node)\n",
    "\n",
    "graph.add_edge(START, 'joke_node')\n",
    "graph.add_edge('joke_node', 'explanation_node')\n",
    "graph.add_edge('explanation_node', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a297a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a30ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "initial_state = {'topic': 'Indian Politics'}\n",
    "\n",
    "workflow.invoke(initial_state, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbce849",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "initial_state = {\"topic\": \"Indians\"}\n",
    "\n",
    "workflow.invoke(initial_state, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "workflow.invoke({\"topic\": \"pizza\"}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e150882",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state_history(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ce62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({\"topic\": \"pasta\"}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517d200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bf153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137735cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "845bdf24",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state(\n",
    "    {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"checkpoint_id\": \"1f078c8d-511f-60fb-8005-1d948efec61e\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.invoke(\n",
    "    None,\n",
    "    {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"checkpoint_id\": \"1f078c8d-511f-60fb-8005-1d948efec61e\",\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03700d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.update_state(\n",
    "    {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"checkpoint_id\": \"1f078c8d-511f-60fb-8005-1d948efec61e\",\n",
    "            \"checkpoint_ns\": \"\",\n",
    "        }\n",
    "    },\n",
    "    {\"topic\": \"samosa\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.invoke(\n",
    "    None,\n",
    "    {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"checkpoint_id\": \"1f078c8d-511f-60fb-8005-1d948efec61e\",\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cad79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b3198",
   "metadata": {},
   "source": [
    "## Fault Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e531db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c887340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\"‚úÖ Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\n",
    "        \"‚è≥ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\"\n",
    "    )\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\"‚úÖ Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"‚ñ∂Ô∏è Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": \"thread-1\"}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\"‚ùå Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Re-run to show fault-tolerant resume\n",
    "print(\"\\nüîÅ Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": \"thread-1\"}})\n",
    "print(\"\\n‚úÖ Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": \"thread-1\"}}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
